# AI Model Training Data Generation (SFT & RLHF)

This project demonstrates my ability to generate training data for fine-tuning large language models (LLMs) using two key techniques:

1. **Supervised Fine-Tuning (SFT)**: I created high-quality prompt-response pairs that would serve as training data for the model.
2. **Reinforcement Learning from Human Feedback (RLHF)**: I evaluated two LLM responses and provided feedback on their quality to aid in model refinement.

## Project Structure:
- `SFT/`: Contains example prompt-response pairs generated for Supervised Fine-Tuning.
- `RLHF/`: Contains example comparisons of LLM outputs with feedback to guide model improvement.

This project highlights my ability to contribute to model fine-tuning by generating high-quality data for both SFT and RLHF.
